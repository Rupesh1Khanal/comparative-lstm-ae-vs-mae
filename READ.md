#  Comparative Study of LSTM-AE vs MAE for Anomaly Detection (NASA C-MAPSS FD001)

This repository contains the full pipeline, experiments, and results for a master’s thesis project comparing **LSTM Autoencoder (LSTM-AE)** and **Masked Autoencoder (MAE)** for anomaly detection on the **NASA C-MAPSS FD001 turbofan engine dataset**.  
The goal is to evaluate the effectiveness of **reconstruction-based** (LSTM-AE) vs **self-supervised masking-based** (MAE) anomaly detection methods.

---

## 📂 Repository Structure

Comparison_of_models/
├── artifacts/ # Generated artifacts: metrics, scores, PR arrays, weights
├── data/ # Raw + processed NASA C-MAPSS FD001 data
├── notebooks/ # Jupyter notebooks for preprocessing, training, visualization
├── runs/ # Per-run experiment summaries (metrics, config, etc.)
├── thesis_env/ # Local Python virtual environment (not versioned)
├── .gitignore # Ignore large/binary artifacts + checkpoints
├── config.yaml # Master config: preprocessing, training, evaluation settings
├── README.md
└── requirements.txt # Reproducible environment specification


### Key Directories

- **`artifacts/`**  
  Stores all derived outputs:
  - `preprocessing_meta.json`, `splits.json`, `yaml_hash.txt` (core reproducibility metadata)  
  - `metrics_*.json`, `scores_*.npy`, `pr_*.npy` (evaluation results)  
  - `*.h5` (trained model weights, checkpoints)  
  - `figures/` (plots generated by visualization notebook)

- **`data/`**  
  Contains raw and prepared versions of the NASA C-MAPSS FD001 dataset.

- **`notebooks/`**  
  - `preprocessing.ipynb` → load, clean, window, scale, split dataset.  
  - `lstm_ae.ipynb` → train & evaluate LSTM Autoencoder pipeline.  
  - `mae.ipynb` → train & evaluate Masked Autoencoder pipeline.  
  - `visualization.ipynb` → generate plots (PR curves, label histograms, etc.).

- **`runs/`**  
  Auto-created folders per experiment run with timestamp + config hash, e.g.:


---

## ⚙️ Installation

1. **Create and activate a virtual environment** (example with `venv`):

```bash
python -m venv thesis_env
# Linux/Mac
source thesis_env/bin/activate
# Windows
thesis_env\Scripts\activate
```


2. **Install dependencies form requirements.txt** :
```bash
pip install -r requirements.txt
```

## 📦 Project Environment

This project was developed with:

Python 3.10

TensorFlow 2.10.1 (GPU-enabled, CUDA 11.2 + cuDNN 8)

NumPy

Pandas

scikit-learn

Matplotlib

PyYAML

## ▶️ Usage

Preprocessing
Run notebooks/preprocessing.ipynb
→ generates normalized sequences, splits, and metadata in artifacts/.

Train LSTM-AE
Run notebooks/lstm_ae.ipynb
→ saves weights (lstm_ae_best.weights.h5), validation/test metrics, PR curves.

Train MAE
Run notebooks/mae.ipynb
→ trains BiLSTM-based MAE with random masking; saves metrics and scores.

Visualization
Run notebooks/visualization.ipynb
→ generates comparative PR curves and class imbalance histograms into artifacts/figures/.

## 📊 Results (FD001)

Validation (best F1 threshold)

LSTM-AE: PR-AUC ≈ 0.84, F1 ≈ 0.74

MAE: PR-AUC ≈ 0.61, F1 ≈ 0.52

Test (raw vs warm-up calibration)

LSTM-AE: PR-AUC (raw) ≈ 0.41, PR-AUC (warm-up) ≈ 0.54

MAE: PR-AUC (raw) ≈ 0.11, PR-AUC (warm-up) ≈ 0.19

👉 LSTM-AE consistently outperforms MAE across validation and test.
👉 MAE shows limited robustness despite masking, indicating higher sensitivity to masking ratio and training stability.

🔄 Reproducibility

All hyperparameters are in config.yaml (sequence length, stride, enc/dec sizes, dropout, learning rate, mask ratios, evaluation thresholds).

Every run stores:

yaml_hash.txt → MD5 fingerprint of config used at preprocessing.

env_snapshot.json → Python + package versions.

run_summary.json → metrics & thresholds for that run.

To fully reproduce:
```bash
python -m venv thesis_env
pip install -r requirements.txt
# Run preprocessing, then lstm_ae.ipynb / mae.ipynb
```

📜 Citation

If you use this repository in academic work, please cite:

@mastersthesis{thesis2025,
  author       = {Rupesh Khanal},
  title        = {Comparative Study of Masked Autoencoders (Self-supervised Learning) and LSTM Autoencoder Baseline for Anomaly Detection in the NASA Turbofan Engine Time-series Dataset},
  school       = {GISMA University of Applied Sciences},
  year         = {2025},
  address      = {Berlin, Germany}
}

🙏 Acknowledgements

NASA Ames Research Center for providing the C-MAPSS turbofan engine degradation dataset.

Kaggle for hosting the dataset version used in this project.

Open-source libraries: TensorFlow, NumPy, scikit-learn, Matplotlib, PyYAML.
